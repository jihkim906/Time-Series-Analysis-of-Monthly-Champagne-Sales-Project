---
title: "4A03Project"
author: "Jihwan Kim"
date: "2025-03-21"
fontsize: 12pt
mainfont: Times New Roman
linestretch: 1
output: 
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Section1: Introduction

The purpose of this project is to apply the time series analysis methods learned in STATS 4A03 to model and forecast monthly Champagne sales for the Perrin Freres label in France. This dataset, originally credited to Makridakis and Wheelwright (1989), provides monthly observations of Champagne sales from January 1964 through September 1972, resulting in a total of 105 data points. Each observation reflects the count of sales (in millions), making it an ideal time series for examining patterns and forecasting future demand.

Understanding historical sales trends is crucial within the wine and spirits industry, where factors such as seasonality, marketing campaigns, consumer behavior, and broader economic conditions can all affect demand. By identifying these patterns in the data—whether they manifest as persistent monthly fluctuations or longer-term trends—producers and distributors can make more informed decisions about inventory management, resource allocation, and strategic planning. From a methodological standpoint, time series analysis techniques are particularly well-suited for detecting such signals: they help isolate underlying trends, quantify seasonal behavior, and evaluate how past observations can inform accurate predictions.

In line with the project guidelines, this introduction establishes the purpose (analyzing and forecasting sales of Champagne), the relevance (improving understanding of consumer demand within a key segment of the beverage industry), the importance (insight-driven production and marketing strategies that minimize waste and optimize profits), and the goal (fitting a suitable time series model to produce robust forecasts and examine underlying time-dependent structures).

Further, this dataset’s relatively long span—close to nine years—facilitates a comprehensive exploration of multiple time series components. Through the steps of model specification, parameter estimation, model diagnostics, and forecast generation, the project will demonstrate the practical application of the statistical techniques learned in class. Specifically, the monthly frequency of the data enables a detailed look at possible cyclical or seasonal trends inherent in Champagne sales (e.g., year-end holiday boosts). Because consumer purchasing behavior can be sensitive to both economic factors and cultural events, it is especially meaningful to quantify and interpret these seasonal effects rigorously.

The remaining sections of this R Markdown report are structured as follows:

-   Section 2: Modeling introduces the time series methods used, including the step-by-step process for identifying, estimating, and selecting the appropriate model. Key plots and exploratory analyses will be presented to justify the final choice of model.
-   Section 3: Results discusses the accuracy of the model’s forecasts and how effectively it captures the behavior of monthly Champagne sales.
-   Section 4: Conclusion reflects on the limitations of the analysis (such as potential data quality issues or unexpected external influences), and proposes directions for future improvements. By bringing together real-world data, established statistical methods, and thoughtful interpretation, this project underscores how time series analysis can guide business strategies and planning in the Champagne industry and beyond.

# Section 2: Modeling

### Library

```{r}
library(ggplot2)
library(TSA)
library(tseries)
library(astsa)

```

### Data Preparation

```{r}
df <- read.csv('/Users/jihwan/Documents/Academic/2024-2025/4A03Project/monthly_champagne_sales.csv')

ts_sales <- ts(df$Sales, start = c(1964, 1), frequency = 12)

print(paste("Missing Values:", sum(is.na(ts_sales))))

```

### Plot the Time Series

```{r}
plot(ts_sales, 
     main = "Monthly Champagne Sales", 
     ylab = "Sales (in millions)", 
     xlab = "Time")
```

### Seasonal Differencing

The time series plot of monthly Champagne sales from 1964 to 1972 shows a strong and repeating seasonal pattern, with sharp peaks occurring approximately every 12 months. In addition to the seasonality, there is a slight upward linear trend in overall sales over time. According to standard time series modeling guidelines, when both trend and seasonality are present, it is appropriate to first apply a seasonal difference (with lag 12 for monthly data) to remove the seasonal component. After this transformation, we can re-evaluate the series to determine whether a first (non-seasonal) difference is also needed to address the remaining trend and achieve stationarity.

```{r}
seasonaldiff <- diff(ts_sales, lag = 12)
plot(seasonaldiff, 
     main = "Seasonally Differenced Monthly Champagne Sales", 
     ylab = "Change in Sales (in millions)", 
     xlab = "Time")
```

After applying a seasonal difference of lag 12 to the monthly Champagne sales data, the resulting time series shows that the seasonality has been effectively removed. The sharp, repeating annual spikes present in the original series are no longer visible. Additionally, the slight upward linear trend observed earlier is no longer apparent in the seasonally differenced series, suggesting that the data may now be sufficiently stationary.

While we could consider applying a first (non-seasonal) difference to further eliminate any potential remaining trend, doing so would increase the complexity of the model. To keep the model as simple as possible, and since no strong trend remains visually or structurally, we proceed using only the seasonally differenced data for further modeling and analysis.

### Starionarity Testing: Dickey-Fuller Test

To statistically confirm whether the seasonally differenced series is stationary, we apply the Dickey-Fuller test. This test evaluates the null hypothesis that the time series contains a unit root (i.e., it is non-stationary), against the alternative hypothesis that the series is stationary.

In this case, the test yields a Dickey-Fuller statistic of -4.0804 with a p-value of 0.01. Since the p-value is less than the 0.05 significance level, we reject the null hypothesis and conclude that the seasonally differenced series is stationary.

This confirms that no additional differencing is needed, and the series is ready for model identification and fitting.

```{r}
seasonaldiff_adf <- adf.test(seasonaldiff)
print(seasonaldiff_adf)
```

### ACF and PACF Analysis

When building models, examining both the Autocorrelation Function (ACF) and the Partial Autocorrelation Function (PACF) provides guidance for identifying autoregressive (AR) and moving average (MA) components, both non-seasonal and seasonal.

-   **ACF**
    -   Detects MA terms through sharp cutoffs in autocorrelations at lower lags (indicating a non-seasonal MA term).\
    -   Shows seasonal MA dependencies when there are significant spikes at or around seasonal lags (e.g., lag 12 for monthly data).
-   **PACF**
    -   Detects AR terms through sharp drops in partial autocorrelations at certain lags (indicating a non-seasonal AR term).\
    -   Shows seasonal AR dependencies if there are significant spikes at multiples of the seasonal period.

By examining both the ACF and PACF for the seasonally differenced Champagne sales data, we can form an initial hypothesis about the orders of the AR and MA components—both seasonal and non-seasonal—to include in our model. Further diagnostic checks will then confirm or refine these selections.

```{r}
par(mfrow = c(1, 2))  
acf(seasonaldiff, lag.max = 50, main = "ACF")
pacf(seasonaldiff, lag.max = 50, main = "PACF")
```

From the ACF of the seasonally differenced series, we observe: - A slight spike at lag 1, potentially indicating a non-seasonal MA(1) component.\
- A slight spike around lag 12, which could suggest a seasonal MA(1) term.

However, neither spike appears strongly significant (they do not clearly rise above the dashed confidence bounds). To keep the model simple, we tentatively choose no non-seasonal MA and no seasonal MA at this stage. We will revisit this assumption later by testing a more complex model to confirm whether these components might improve the fit.

From the PACF of the seasonally differenced series, we observe: - A small spike at lag 1, which may indicate a non-seasonal AR(1) component, but it is only marginally above the confidence band, so we treat it as insignificant for now.\
- A significant spike around lag 12–13, suggesting the presence of a seasonal AR(1) term. Because this spike is clearly above the confidence interval, we decide to include seasonal AR(1) in our tentative model specification.

Based on this initial inspection, we propose a model with $$\text{ARIMA}(0,0,0) \times (1,1,0)_{12}$$ We will compare this simpler specification with alternative models (for example, adding non-seasonal MA(1), seasonal MA(1), or non-seasonal AR(1)) to ensure that our final choice captures the underlying data patterns effectively.

### Model Fitting and Residual Analysis for $$\text{ARIMA}(0,0,0) \times (1,1,0)_{12}$$

```{r}
model1 <- sarima(ts_sales, 0, 0, 0, 1, 1, 0, 12)
```

### Residual Analysis

-   Standardized Residuals: The residual plot shows no obvious patterns or trends, suggesting that the residuals behave like white noise.\
-   ACF of Residuals: Aside from a slight spike at one early lag, most autocorrelations lie well within the confidence bounds, indicating that the residuals are largely uncorrelated.\
-   Normal Q-Q Plot: The points broadly follow the straight line (except for some deviation at the tails), which is reasonably consistent with a normal distribution.\
-   Ljung-Box Test: Except for a few early lags, the p-values exceed 0.05, implying no significant autocorrelation is left in the residuals. However, the few lower p-values may suggest that incorporating an additional term (Seasonal MA, non-seasonal MA or non-seasonal AR) could further improve the model fit.

Overall, the residual analysis supports the adequacy of the current model's assumptions, but there may be room for minor refinements if those early-lag correlations are deemed problematic.

### Model Fitting and Residual Analysis for $$\text{ARIMA}(0,0,1) \times (1,1,0)_{12}$$

```{r}
model2 <- sarima(ts_sales, 0, 0, 1, 1, 1, 0, 12)
```

-   Standardized Residuals: There are no obvious patterns or trends, suggesting the residuals resemble white noise.
-   ACF of Residuals: Apart from a minor spike around lag 1, all autocorrelations lie well within the confidence bounds, indicating little to no autocorrelation.
-   Normal Q-Q Plot: The points mostly follow the straight line, with only slight deviation at the tails, supporting the assumption of normality in the residuals.
-   Ljung-Box Test: The p-values are now consistently above 0.05 (an improvement over the previous model), indicating no significant autocorrelation remains.

Given these results, the residuals appear to satisfy the key assumptions. Therefore, we can tentatively accept this model specification.

# Result

## Forecaset

```{r}

sarima.for(ts_sales, 60, 0, 0, 1, 1, 1, 0, 12, main = "24 Months Forecast of Champagne Sales",ylab = "Sales (in millions)", 
     xlab = "Time")



```
